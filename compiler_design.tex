\documentclass[12pt, a4paper]{article}

% Preamble

\usepackage[margin=1in]{geometry}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{cprotect}
\usepackage{enumerate}
\usepackage{pdfpages}

\newcommand{\para}[1]{\paragraph{#1}\mbox{}\\}
\newcommand{\icode}{\texttt}

\title{Compiler Design Document}
\date{\today}
\author{Richard Peng, Jane Wang}
% Document

\begin{document}

\maketitle

\section{Introduction}

For the first stage of our compiler, we wanted to create a general purpose scanner and parser, that's not specifically tied to Joos 1W rules. We've built these into Python modules that contain some core data structures, as well as generic scanning and parsing algorithms, such as Maximal Munch and Shift-Reduce. A separate module contains all of the Joos specific constructs. \\

We wrote our compiler in Python 2.7, and used GitHub to host the project repository. The report will first give an overview of the directory layout of the repository, the overall architecture of our compiler, and then a description of each component. Finally, it will discuss some of the challenges that we faced during planning and implementations, and our solutions to these challenges.

\section{Directory Structure}

\subsection{\texttt{compiler/}}

This module contains a Maximum Munch scanner, a Shift-Reduce parser, as well as defines a few errors that may arise - for example when the scanner encounters an invalid token, or the parser is expecting a different token.

\subsection{\texttt{extern/} (Omitted from submissions)}

Contains external helpers that were used, such as the Jlalr parse table generator, and the Marmoset test files.
 
\subsection{\texttt{generated/}}

Contains generated files that are not placed under version control. This includes a \verb|joos.cfg| (more about how this was generated later), as well as a \verb|joos.lr1| (the output from the Jlalr generator).

\subsection{\texttt{joos/}}

All of the Joos 1W specific modules are put here. Contains Joos grammar files, the beginnings of an Abstract Syntax, regular expressions for Joos 1W tokens, as well as some Joos specific visitors that will aid in building the AST and weeding.

\subsection{\texttt{structs/}}

Core data structures that are required for many functions. This includes Finite State Machines, Regular Expressions, and Context-Free Grammars.

\subsection{\texttt{scripts/}}

Contains a helper script that can convert a custom CFG specification format to one that is accepted by the Jlalr token generator.


\subsection{\texttt{./joosc}}

Executable program entry point. Takes in a path to a Joos file as an argument, and returns 0 if it is valid Joos, 42 if it is not.

\section{Compiler Architecture}

As advised, we divided our compiler into three stages: Scanning, Parsing and Weeding. The scanner takes in a source file and outputs tokens. The parser then takes the tokens and builds a derivation in the form of a parse tree. Finally, the weeder traverses the parse tree and validates each node. We allowed to grammar to be more less strict (for example, when evaluating modifiers), as to prevent conflicts in the LALR1 machine. The weeding step is necessary to validate constraints that were omitted from the grammar.

\subsection{Scanning}

Before the scanner is invoked, all the state machines required for parsing Joos tokens are created. These state machines are generated by composition of regular expressions. Our regular expressions are simply NFAs, as well as some operators that can combine regular expressions. One regular expression is created for each keyword. Literals and identifiers have special regular expressions that matches Java literals (integers, string, etc...) and identifiers (name, etc). There is a list of all the exported tokens (in \verb|exports.py|), which is used by the scanner. \\

The scanner takes a map (from token types to a regular expression corresponding to that type), as well as an input file as arguments, and generates token types using the Maximal Munch algorithm. 

\end{document}
